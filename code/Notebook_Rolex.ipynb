{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_Rolex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulaheess/DataMiningUniL/blob/main/code/Notebook_Rolex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee1dPZ5x3h76"
      },
      "source": [
        "<h1> UNIL Team Rolex\n",
        "\n",
        "<h3> Preparation to start working - import necessary methods etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owgx-k91Ov_g"
      },
      "source": [
        "**Remarks from Slack:** Basically we want to have your baseline solutions in that table. So without any data cleaning and pre-processing, who would the models mentioned in the table would perform (for each model you are also supposed to do hyper-parameter optimization to find the best hyper-parameters). This will give you the baseline accuracies that you can try to improve further by doing data preprocessing/cleaning or by using other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNRi80vlEyt1",
        "outputId": "9beb4ecc-eb59-469b-84d9-8af2a3c0c756"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 58.2 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 21.4 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp-iRswNE44F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import string\n",
        "import csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leHXJLnvC3c2"
      },
      "source": [
        "#Classifier\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "#Other\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn. preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from spacy import displacy\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from spacy.lang.fr import French"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBpIhxQR7iuC"
      },
      "source": [
        "<h3> First preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzA0kkN1EKG2"
      },
      "source": [
        "nlp = spacy.load('fr_core_news_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiLVW789Q1HU"
      },
      "source": [
        "stop_words=spacy.lang.fr.stop_words.STOP_WORDS\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0efssDo2QJ-O"
      },
      "source": [
        "def spacy_tokenizer(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = nlp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "    ## alternative way\n",
        "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS9S8XIjQUa1"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer()\n",
        "count_vector = CountVectorizer()\n",
        "#with preprocessing\n",
        "#tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbxvE-3a4b55"
      },
      "source": [
        "<h3> Getting started - text analytics per classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kROIrRXZ6V8i"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZA9m_yvB_vQ",
        "outputId": "5b7d4c42-4910-4933-f095-704791fa62be"
      },
      "source": [
        "lr_data=pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/training_data.csv', index_col='id')\n",
        "lr_test_df = pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/unlabelled_test_data.csv', index_col='id')\n",
        "lr_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4800, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tILch0iP2cj"
      },
      "source": [
        "X_lr = lr_data['sentence']\n",
        "ylabels_lr = lr_data['difficulty']\n",
        "\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr, ylabels_lr, test_size=0.2, random_state=1234, stratify=ylabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf3Pp3f9P-Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6ca6a0-d4b0-4bd4-d486-89d50b8fe474"
      },
      "source": [
        "# Define classifier\n",
        "lreg = LogisticRegression()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', lreg)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train_lr, y_train_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f3d1ee16200>)),\n",
              "                ('classifier', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggeYhJXwRtFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1346ad8d-589b-406f-df2e-1536afec2254"
      },
      "source": [
        "# Predictions\n",
        "y_pred_lr = pipe.predict(X_test_lr)\n",
        "\n",
        "accuracy_score(y_test_lr,y_pred_lr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41354166666666664"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJp_X2jV6lP4"
      },
      "source": [
        "**kNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmCSWQGs68Eq"
      },
      "source": [
        "knn_data=pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/training_data.csv', index_col='id')\n",
        "knn_test_df = pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/unlabelled_test_data.csv', index_col='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPjANU9g7LiI"
      },
      "source": [
        "X_knn = knn_data['sentence']\n",
        "ylabels_knn = knn_data['difficulty']\n",
        "\n",
        "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_knn, ylabels_knn, test_size=0.2, random_state=1234, stratify=ylabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys-DfQ9Qg358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c64037-f7ac-48d0-fd09-9d5b3d8d57b8"
      },
      "source": [
        "# Define classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', knn)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train_knn, y_train_knn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f3d1ee16200>)),\n",
              "                ('classifier', KNeighborsClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPglJHd8gsVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22deeb0d-4821-405a-9640-cf26c13064ae"
      },
      "source": [
        "y_pred_knn = pipe.predict(X_test_knn)\n",
        "\n",
        "accuracy_score(y_test_knn,y_pred_knn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.171875"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYol3GFa6wzs"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VcEoDF-6_rZ"
      },
      "source": [
        "tree_data=pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/training_data.csv', index_col='id')\n",
        "tree_test_df = pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/unlabelled_test_data.csv', index_col='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSPymGOk7PfG"
      },
      "source": [
        "X_tree = tree_data['sentence']\n",
        "ylabels_tree = tree_data['difficulty']\n",
        "\n",
        "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(X_tree, ylabels_tree, test_size=0.2, random_state=1234, stratify=ylabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFIl3VHjWZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7e8f84-3925-4d4f-9d83-ffdfb208731c"
      },
      "source": [
        "# Define classifier\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', tree)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train_tree, y_train_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f3d1ee16200>)),\n",
              "                ('classifier', DecisionTreeClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGPV-iKDifr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3011e01c-e340-4af9-8f04-3893197fa2db"
      },
      "source": [
        "y_pred_tree = pipe.predict(X_test_tree)\n",
        "\n",
        "accuracy_score(y_test_tree,y_pred_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35208333333333336"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-NDltT62B0"
      },
      "source": [
        "**Random Forest**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSuskT3GEIc9"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "m_IMuTls7C1j",
        "outputId": "40b18820-8882-47cc-a2b0-1639ed1e66a2"
      },
      "source": [
        "rf_data=pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/training_data.csv', index_col='id')\n",
        "rf_test_df = pd.read_csv('https://raw.githubusercontent.com/chadi-aebi/DMML2021_Rolex/main/data/unlabelled_test_data.csv', index_col='id')\n",
        "rf_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentence difficulty\n",
              "id                                                              \n",
              "0   Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1   Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2   Le test de niveau en français est sur le site ...         A1\n",
              "3            Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   Dans les écoles de commerce, dans les couloirs...         B1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bfOAuQbH4DU"
      },
      "source": [
        "#stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFia3ER7Ygu"
      },
      "source": [
        "X_rf = rf_data['sentence']\n",
        "ylabels_rf = rf_data['difficulty']\n",
        "\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, ylabels_rf, test_size=0.2, random_state=1234, stratify=ylabels_rf)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0MTWwJkhh5p"
      },
      "source": [
        "# Define classifier\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c3bxy72SC3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980864f1-384b-44bf-d1a2-9a47a64b1745"
      },
      "source": [
        "\n",
        "# Create pipeline with tfidf\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', rfc)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train_rf, y_train_rf)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG3X64vahNoI",
        "outputId": "937adee6-b94d-499d-c0bc-79ef4640349a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Tuning Hyperparameters\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 25)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [50, 131, 212, 293, 375, 456, 537, 618, 700, 781, 862, 943, 1025, 1106, 1187, 1268, 1350, 1431, 1512, 1593, 1675, 1756, 1837, 1918, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmbrlJcrhU8Y",
        "outputId": "2648eaab-f423-4b1c-c030-983426209105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Crossvalidation\n",
        "rf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 2, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "# Create pipeline with tfidf\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', rf_random)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train_rf, y_train_rf)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier',\n",
              "                 RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "                                    n_iter=2, n_jobs=-1,\n",
              "                                    param_distributions={'bootstrap': [True,\n",
              "                                                                       False],\n",
              "                                                         'max_depth': [10, 20,\n",
              "                                                                       30, 40,\n",
              "                                                                       50, 60,\n",
              "                                                                       70, 80,\n",
              "                                                                       90, 100,\n",
              "                                                                       110,\n",
              "                                                                       None],\n",
              "                                                         'max_features': ['auto',\n",
              "                                                                          'sqrt'],\n",
              "                                                         'min_samples_leaf': [1,\n",
              "                                                                              2,\n",
              "                                                                              4],\n",
              "                                                         'min_samples_split': [2,\n",
              "                                                                               5,\n",
              "                                                                               10],\n",
              "                                                         'n_estimators': [50,\n",
              "                                                                          131,\n",
              "                                                                          212,\n",
              "                                                                          293,\n",
              "                                                                          375,\n",
              "                                                                          456,\n",
              "                                                                          537,\n",
              "                                                                          618,\n",
              "                                                                          700,\n",
              "                                                                          781,\n",
              "                                                                          862,\n",
              "                                                                          943,\n",
              "                                                                          1025,\n",
              "                                                                          1106,\n",
              "                                                                          1187,\n",
              "                                                                          1268,\n",
              "                                                                          1350,\n",
              "                                                                          1431,\n",
              "                                                                          1512,\n",
              "                                                                          1593,\n",
              "                                                                          1675,\n",
              "                                                                          1756,\n",
              "                                                                          1837,\n",
              "                                                                          1918,\n",
              "                                                                          2000]},\n",
              "                                    random_state=42, verbose=2))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig3LhodbDmot",
        "outputId": "c70c80b5-182f-42dd-dbe1-e36ae1a8a176"
      },
      "source": [
        "# Define classifier\n",
        "#rfc = RandomForestClassifier()\n",
        "\n",
        "# Create pipeline with count\n",
        "#pipe = Pipeline([('vectorizer', count_vector),\n",
        "                 #('classifier', rfc)])\n",
        "\n",
        "# Fit model on training set\n",
        "#pipe.fit(X_train_rf, y_train_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
              "                ('classifier', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1tDTARLjbnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbd341e-aad9-4f93-d303-ee4990b4b6a7"
      },
      "source": [
        "y_pred_rf = pipe.predict(X_test_rf)\n",
        "\n",
        "accuracy_score(y_test_rf,y_pred_rf)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4427083333333333"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFIi0cuR_0Bh"
      },
      "source": [
        "y_pred_test=pipe.predict(rf_test_df['sentence'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Wv3TWRkWC02p",
        "outputId": "a51dbf09-9a46-4fcd-982e-c9496c6263f2"
      },
      "source": [
        "submission_test = pd.DataFrame(y_pred_test, columns=['difficulty'])\n",
        "submission_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     difficulty\n",
              "0            A1\n",
              "1            B1\n",
              "2            A1\n",
              "3            A1\n",
              "4            C2\n",
              "...         ...\n",
              "1195         C2\n",
              "1196         A2\n",
              "1197         C2\n",
              "1198         A1\n",
              "1199         A1\n",
              "\n",
              "[1200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFMazOxqCbAO"
      },
      "source": [
        "\n",
        "submission_test.to_csv('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIrshLbcI1mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d53dd5-a59f-4521-a92d-ce4bed51b799"
      },
      "source": [
        "#Vectorizing - Word Embeddings\n",
        "with nlp.disable_pipes():\n",
        "    vectors = np.array([nlp(lang.sentence).vector for idx, lang in rf_data.iterrows()])\n",
        "    \n",
        "vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4800, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFsQtcUMIpim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}